<h1 id="provisionnement">Provisionnement</h1>
<h2 id="modÃ¨le-chain-ladder">ModÃ¨le Chain Ladder</h2>
<div class="definition">
<p><span>Algorithme Chain Ladder</span> Lâ€™algorithme Chain Ladder repose
sur les deux hypothÃ¨ses suivantes :</p>
<ul>
<li><p><strong>(CL1))</strong> les montants cumulatifs pour diffÃ©rentes
annÃ©es de survenance</p></li>
<li><p><strong>(CL2))</strong> il existe des facteurs de dÃ©veloppement
(ou facteurs multiplicatifs ou facteurs de dÃ©roulement) <span
class="math inline"><em>Î»</em><sub>1</sub>,â€†â€¦,â€†<em>Î»</em><sub><em>J</em>â€…âˆ’â€…1</sub></span>
tels que <span
class="math inline"><em>Î»</em><sub><em>j</em></sub></span> reprÃ©sente le
dÃ©veloppement de la pÃ©riode <span class="math inline"><em>j</em></span>
Ã  la pÃ©riode <span class="math inline"><em>j</em>â€…+â€…1</span>, ou encore
de la colonne <span class="math inline"><em>j</em></span> Ã  la colonne
<span class="math inline"><em>j</em>â€…+â€…1</span> dans un triangle de
dÃ©veloppement : <span
class="math inline"><em>C</em><em>i</em>(<em>j</em>+1)â€„=â€„<em>Î»</em><em>j</em><em>C</em><em>i</em><em>j</em></span>
pour <span class="math inline"><em>j</em>â€„=â€„1,â€†â€¦,â€†<em>J</em>â€…âˆ’â€…1</span>
et <span
class="math inline"><em>i</em>â€„=â€„1,â€†â€¦,â€†<em>J</em></span></p></li>
</ul>
</div>
<p>Les facteurs de dÃ©veloppement <span
class="math inline"><em>Î»</em><sub><em>k</em></sub></span> sont estimÃ©s
Ã  lâ€™aide des observations: <span
class="math display">$$\widehat{\lambda}_k =
\frac{\sum\limits_{i=1}^{J-k}C_{i(k+1)}}{\sum \limits_{i=1}^{J-k}C_{ik}}
pour k=1,...,J-1$$</span><br />
A partir de ces estimateurs <span
class="math inline"><em>Î»Ì‚</em><sub><em>k</em></sub></span>, on peut
estimer le cout total pour chacune des annÂ´ees de survenance et obtenir
une estimation pour la rÃ©serve. <span
class="math display"><em>CÌ‚</em><sub><em>i</em><em>J</em></sub>â€„=â€„(<em>Î»Ì‚</em><sub><em>J</em>â€…âˆ’â€…<em>i</em>â€…+â€…1</sub>Ã—...Ã—<em>Î»Ì‚</em><sub><em>J</em>â€…âˆ’â€…1</sub>)<em>C</em><sub><em>i</em>(<em>J</em>âˆ’<em>i</em>+1)</sub></span></p>
<p><span
class="math display"><em>RÌ‚</em><sub><em>i</em></sub>â€„=â€„<em>CÌ‚</em><sub><em>i</em><em>J</em></sub>â€…âˆ’â€…<em>C</em><sub><em>i</em>(<em>J</em>âˆ’<em>i</em>+1)</sub></span>
<span
class="math display"><em>RÌ‚</em>â€„=â€„âˆ‘<em>RÌ‚</em><sub><em>i</em></sub></span></p>
<h2 id="modÃ¨le-mack">ModÃ¨le Mack</h2>
<div class="definition">
<p><span>ModÃ¨le de Mack</span> Les hypothÃ¨ses du modÃ¨le de Mack sont</p>
<ul>
<li><p><strong>(MC1)</strong> indÃ©pendance par ligne : <span
class="math inline">(<em>C</em><sub><em>i</em><em>j</em></sub>)<sub><em>j</em>â€„=â€„1,â€†...,â€†<em>J</em></sub></span>
et <span
class="math inline">(<em>C</em><sub><em>i</em>â€²<em>j</em></sub>)<sub><em>j</em>â€„=â€„1,â€†...,â€†<em>J</em></sub></span>
sont indÃ©pendants pour <span
class="math inline"><em>i</em>â€„â‰ â€„<em>i</em>â€²</span> ;</p></li>
<li><p><strong>(MC2)</strong> on a la relation <span
class="math inline"><em>E</em>[<em>C</em><sub><em>i</em><em>j</em></sub>|<em>C</em><sub><em>i</em>1</sub>,...,<em>C</em><sub><em>i</em>(<em>j</em>âˆ’1)</sub>]â€„=â€„<em>Î»</em><sub><em>j</em>â€…âˆ’â€…1</sub><em>C</em><sub><em>i</em>(<em>j</em>âˆ’1)</sub>,â€†<em>j</em>â€„=â€„2,â€†...,â€†<em>J</em></span></p></li>
</ul>
</div>
<h3 id="estimateur-du-cout-Ã -lultime">Estimateur du cout Ã  lâ€™ultime</h3>
<div class="theoreme">
<p><span>Proposition 1</span> Sous les hypothÃ¨ses <strong>(MC1)</strong>
et <strong>(MC2)</strong>, on a <span
class="math display"><em>E</em>[<em>C</em><sub><em>i</em><em>J</em></sub>|ğ’Ÿ<sub><em>J</em></sub>]â€„=â€„<em>E</em>[<em>C</em><sub><em>i</em><em>J</em></sub>|<em>C</em><sub><em>i</em>(<em>J</em>âˆ’<em>i</em>+1)</sub>]â€„=â€„<em>Î»</em><sub><em>J</em>â€…âˆ’â€…1</sub><em>Î»</em><sub><em>J</em>â€…âˆ’â€…2</sub>...<em>Î»</em><sub><em>J</em>â€…âˆ’â€…<em>i</em>â€…+â€…1</sub><em>C</em><sub><em>i</em>(<em>J</em>âˆ’<em>i</em>+1)</sub>,â€†1â€„â‰¤â€„<em>i</em>â€„â‰¤â€„<em>J</em></span></p>
</div>
<div class="theoreme">
<p><span>Proposition 2</span> Sous les hypothÃ¨ses <strong>(MC1)</strong>
et <strong>(MC2)</strong>,</p>
<ol>
<li><p>Sachant <span class="math inline">â„¬<sub><em>j</em></sub></span> ,
lâ€™estimateur <span
class="math inline"><em>Î»Ì‚</em><sub><em>j</em></sub></span> est sans
biais pour <span
class="math inline"><em>Î»</em><sub><em>j</em></sub></span>; et</p></li>
<li><p>lâ€™estimateur <span
class="math inline"><em>Î»Ì‚</em><sub><em>j</em></sub></span> est sans
biais pour <span
class="math inline"><em>Î»</em><sub><em>j</em></sub></span></p></li>
</ol>
</div>
<div class="theoreme">
<p><span>Proposition 3</span> Sous les hypothÃ¨ses <strong>(MC1)</strong>
et <strong>(MC2)</strong>,</p>
<ol>
<li><p>Sachant <span
class="math inline"><em>C</em><sub><em>i</em>(<em>J</em>âˆ’<em>i</em>+1)</sub></span>,
<span
class="math inline"><em>CÌ‚</em><sub><em>i</em><em>J</em></sub></span> est
un estimateur sans biais pour <span
class="math inline"><em>E</em>[<em>C</em><sub><em>i</em><em>J</em></sub>|<em>C</em><sub><em>i</em>(<em>J</em>âˆ’<em>i</em>+1)</sub>]</span></p></li>
<li><p><span
class="math inline"><em>CÌ‚</em><sub><em>i</em><em>J</em></sub></span> est
sans biais pour <span
class="math inline"><em>E</em>[<em>C</em><sub><em>i</em><em>J</em></sub>]</span></p></li>
<li><p>les estimateurs <span
class="math inline"><em>Î»Ì‚</em><sub>1</sub>,â€†...,â€†<em>Î»Ì‚</em><sub><em>j</em></sub></span>
sont non correlÃ©s</p></li>
</ol>
</div>
<h3 id="estimateur-pour-lerreur-de-prÃ©diction">Estimateur pour lâ€™erreur
de prÃ©diction</h3>
<p>Une mÃ©thode stochastique a lâ€™avantage de permettre lâ€™estimation de
lâ€™erreur de prÃ©diction.Pour le modÃ¨le de Mack, il faut modifier
(complÃ©ter) la seconde hypothÃ¨se afin de pouvoir calculer lâ€™erreur de
prÃ©vision :</p>
<p><span class="math display">$$\widehat{\sigma}_{j^2} = \frac{1}{J-j-1}
\sum \limits_{i=1}^{J-j}C_{ij} \left( \frac{C_{i(j+1)}}{C_{ij}} -
\widehat{\lambda}_j  \right)^2$$</span></p>
<p><span class="math display">$$\widehat{\sigma}_{J-1}^2 = min
\left\{  \frac{\widehat{\sigma}_{J-2}^4}{\widehat{\sigma}_{J-3}^2}, min
\left\{  \widehat{\sigma}_{J-3}^2, \widehat{\sigma}_{J-2}^2 \right\}
\right\}$$</span></p>
<div class="theoreme">
<p><span>Proposition 4</span> Sous les hypothÃ¨ses <strong>(MC1)</strong>
et <strong>(MC2)</strong>, on a</p>
<ol>
<li><p>sachant <span
class="math inline">â„¬<sub><em>j</em></sub>,</span>lâ€™estimateur <span
class="math inline"><em>ÏƒÌ‚</em><sub><em>j</em></sub><sup>2</sup></span> ;
est sans biais</p></li>
<li><p>lâ€™estimateur <span
class="math inline"><em>ÏƒÌ‚</em><sub><em>j</em></sub><sup>2</sup></span>
est sans biais pour <span
class="math inline"><em>Ïƒ</em><sub><em>j</em></sub><sup>2</sup></span></p></li>
</ol>
</div>
<div class="definition">
<p><span>Erreur quadratique moyenne de prÃ©diction</span> Pour une
variable alÃ©atoire <span class="math inline"><em>X</em></span>, on
suppose que <span class="math inline"><em>XÌ‚</em></span> est un
estimateur <span class="math inline">â„¬</span>-mesurable pour <span
class="math inline"><em>E</em>[<em>X</em>|ğ’Ÿ]</span> et un prÃ©dicteur
<span class="math inline">ğ’Ÿ</span>-mesurable pour <span
class="math inline"><em>X</em></span>. On dÃ©finit lâ€™erreur quadratique
moyenne conditionnelle de prÃ©diction par</p>
<p><span class="math display">$$\begin{split}
MSEP_{X|\mathcal{D}}(\widehat{X}) &amp; = E \left[ \left( \widehat{X} -
X \right)^2 | \mathcal{D}  \right] \\
                                  &amp; =
\underbrace{Var\left[X|\mathcal{D} \right]}_{\mbox{erreur stochastique}}
+ \underbrace{ \left( \widehat{X} - E \left[X|\mathcal{D} \right]
\right)^2}_{\mbox{erreur d'estimation}}
\end{split}$$</span></p>
</div>
<h4 id="erreur-stochastique">Erreur stochastique</h4>
<p>Pour une annÃ©e de survenance <span
class="math inline"><em>i</em>â€„&gt;â€„1</span>, on a: <span
class="math display">$$Var[C_{iJ}| \mathcal{D}_J] =
\sigma_{J-1}^2C_{i(J-i+1)} = \prod_{m=J-i+1}^{J-2} \lambda_m +
\lambda_{J-1}^2 Var\left[ C_{i(J-1)}|C_{i(J-i+1)}  \right]$$</span>
<span class="math display">$$Var[C_{iJ}| C_{i(J-i+1)} ] = \left( E\left[
C_{iJ}|C_{i(J-i+1)}  \right]  \right)^2 \sum \limits_{j=J-i+1}^{J-1}
\frac{\sigma_j^2/\lambda_j^2}{E[C_{ij}|C_{i(J-i+1)}]}$$</span></p>
<h4 id="erreur-destimation">Erreur dâ€™estimation</h4>
<p><span class="math display">$$\widehat{MSEP}_{C_{ij}|\mathcal{D}_J}^B
(\widehat{C}_{iJ})   \approx C_{iJ}^2 \sum \limits_{i=J-i+1}^{J-1}
\frac{\sigma_j^2}{\lambda_j^2} \left( \frac{1}{C_{ij}}
+\frac{1}{\sum_{i=1}^{J-j}C_{ij}} \right)$$</span></p>
<div class="theoreme">
<p><span>Proposition 5</span> Lâ€™estimateur de lâ€™erreur quadratique
moyenne conditionnelle de prÃ©diction pour lâ€™ensemble des annÃ©es de
survenance est donnÃ© par <span
class="math display">$$\begin{split}                                  
    \widehat{MSEP}_{\sum_i C_{iJ}|\mathcal{D}_J}^A  \left(
\sum_{i=1}^{J}\widehat{C}_{iJ} \right) = \sum_{i=1}^J
\widehat{MSEP}_{C_{iJ}|\mathcal{D}_J}^A(\widehat{C}_{iJ}) \\
   + 2\sum_{1 \leq i &lt; k \leq J} C_{i(J-i+1)}\widehat{C}_{k(J-i+1)}
\left( \prod \limits_{j=J-i+1}^{J-1} \left( \widehat{\lambda}_j^2 +
\frac{\sigma_j^2}{\sum_{i=1}^{J-j} \widehat{C}_{ij}} \right) \prod
\limits_{j=J-i+1}^{J-1} \widehat{\lambda}_j^2 \right)
  \end{split}$$</span></p>
</div>
